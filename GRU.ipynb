{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebb12911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1793</th>\n",
       "      <th>1794</th>\n",
       "      <th>1795</th>\n",
       "      <th>1796</th>\n",
       "      <th>1797</th>\n",
       "      <th>1798</th>\n",
       "      <th>1799</th>\n",
       "      <th>1800</th>\n",
       "      <th>1801</th>\n",
       "      <th>1802</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004230</td>\n",
       "      <td>-0.000280</td>\n",
       "      <td>-0.013906</td>\n",
       "      <td>-0.002544</td>\n",
       "      <td>0.027433</td>\n",
       "      <td>0.058300</td>\n",
       "      <td>0.051670</td>\n",
       "      <td>0.071857</td>\n",
       "      <td>0.080653</td>\n",
       "      <td>0.047917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016692</td>\n",
       "      <td>-0.018566</td>\n",
       "      <td>-0.017361</td>\n",
       "      <td>-0.017919</td>\n",
       "      <td>-0.016680</td>\n",
       "      <td>-0.016650</td>\n",
       "      <td>-0.013097</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012482</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.067856</td>\n",
       "      <td>0.071552</td>\n",
       "      <td>0.078103</td>\n",
       "      <td>0.040353</td>\n",
       "      <td>-0.001059</td>\n",
       "      <td>-0.018580</td>\n",
       "      <td>-0.026813</td>\n",
       "      <td>-0.011280</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008210</td>\n",
       "      <td>-0.010408</td>\n",
       "      <td>-0.011459</td>\n",
       "      <td>-0.011747</td>\n",
       "      <td>-0.010394</td>\n",
       "      <td>-0.008070</td>\n",
       "      <td>-0.004354</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012127</td>\n",
       "      <td>0.028458</td>\n",
       "      <td>0.062075</td>\n",
       "      <td>0.052611</td>\n",
       "      <td>0.022942</td>\n",
       "      <td>-0.010017</td>\n",
       "      <td>-0.023151</td>\n",
       "      <td>-0.028515</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.008450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>-0.002560</td>\n",
       "      <td>-0.003020</td>\n",
       "      <td>-0.004190</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052964</td>\n",
       "      <td>0.074319</td>\n",
       "      <td>0.110670</td>\n",
       "      <td>0.108490</td>\n",
       "      <td>0.091825</td>\n",
       "      <td>0.056989</td>\n",
       "      <td>0.029337</td>\n",
       "      <td>-0.016724</td>\n",
       "      <td>-0.042265</td>\n",
       "      <td>-0.053983</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001209</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>-0.002148</td>\n",
       "      <td>-0.009200</td>\n",
       "      <td>-0.010653</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.020462</td>\n",
       "      <td>-0.030787</td>\n",
       "      <td>-0.008617</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>0.045046</td>\n",
       "      <td>0.042136</td>\n",
       "      <td>0.045037</td>\n",
       "      <td>0.045182</td>\n",
       "      <td>0.025113</td>\n",
       "      <td>0.021730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006369</td>\n",
       "      <td>-0.006614</td>\n",
       "      <td>-0.004698</td>\n",
       "      <td>-0.007279</td>\n",
       "      <td>-0.006861</td>\n",
       "      <td>-0.006161</td>\n",
       "      <td>-0.006113</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20745</th>\n",
       "      <td>1.871600</td>\n",
       "      <td>1.648800</td>\n",
       "      <td>1.608900</td>\n",
       "      <td>1.802300</td>\n",
       "      <td>1.475000</td>\n",
       "      <td>1.390700</td>\n",
       "      <td>1.137800</td>\n",
       "      <td>1.289600</td>\n",
       "      <td>0.963750</td>\n",
       "      <td>1.022200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.497640</td>\n",
       "      <td>-0.432590</td>\n",
       "      <td>-0.414760</td>\n",
       "      <td>-0.363110</td>\n",
       "      <td>-0.329190</td>\n",
       "      <td>-0.460960</td>\n",
       "      <td>-0.621920</td>\n",
       "      <td>9</td>\n",
       "      <td>300</td>\n",
       "      <td>20746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20746</th>\n",
       "      <td>1.889400</td>\n",
       "      <td>2.022700</td>\n",
       "      <td>0.817300</td>\n",
       "      <td>-0.505840</td>\n",
       "      <td>2.462200</td>\n",
       "      <td>3.814200</td>\n",
       "      <td>2.661000</td>\n",
       "      <td>2.651200</td>\n",
       "      <td>1.991400</td>\n",
       "      <td>4.427300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208820</td>\n",
       "      <td>-0.288930</td>\n",
       "      <td>-0.320880</td>\n",
       "      <td>-0.379540</td>\n",
       "      <td>-0.408210</td>\n",
       "      <td>-0.507970</td>\n",
       "      <td>-0.548040</td>\n",
       "      <td>9</td>\n",
       "      <td>300</td>\n",
       "      <td>20747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20747</th>\n",
       "      <td>1.269500</td>\n",
       "      <td>1.312200</td>\n",
       "      <td>0.725570</td>\n",
       "      <td>0.531290</td>\n",
       "      <td>0.958420</td>\n",
       "      <td>-0.049679</td>\n",
       "      <td>1.223100</td>\n",
       "      <td>1.837000</td>\n",
       "      <td>0.989740</td>\n",
       "      <td>1.882600</td>\n",
       "      <td>...</td>\n",
       "      <td>1.218500</td>\n",
       "      <td>1.125400</td>\n",
       "      <td>0.639470</td>\n",
       "      <td>0.277320</td>\n",
       "      <td>0.172710</td>\n",
       "      <td>-0.002894</td>\n",
       "      <td>0.023955</td>\n",
       "      <td>9</td>\n",
       "      <td>300</td>\n",
       "      <td>20748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20748</th>\n",
       "      <td>-5.562200</td>\n",
       "      <td>-2.797000</td>\n",
       "      <td>-2.353300</td>\n",
       "      <td>-3.075600</td>\n",
       "      <td>-4.136100</td>\n",
       "      <td>-4.028800</td>\n",
       "      <td>-0.580260</td>\n",
       "      <td>0.346070</td>\n",
       "      <td>-2.631700</td>\n",
       "      <td>-2.790000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246670</td>\n",
       "      <td>-0.209020</td>\n",
       "      <td>-0.128670</td>\n",
       "      <td>-0.104730</td>\n",
       "      <td>-0.131960</td>\n",
       "      <td>-0.150780</td>\n",
       "      <td>-0.187320</td>\n",
       "      <td>9</td>\n",
       "      <td>300</td>\n",
       "      <td>20749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20749</th>\n",
       "      <td>0.838100</td>\n",
       "      <td>-1.211600</td>\n",
       "      <td>-0.567180</td>\n",
       "      <td>-0.555320</td>\n",
       "      <td>-0.644960</td>\n",
       "      <td>-0.232160</td>\n",
       "      <td>0.367070</td>\n",
       "      <td>-0.040700</td>\n",
       "      <td>0.185980</td>\n",
       "      <td>-0.009721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261620</td>\n",
       "      <td>0.119120</td>\n",
       "      <td>0.004095</td>\n",
       "      <td>0.006755</td>\n",
       "      <td>0.013448</td>\n",
       "      <td>0.027566</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>9</td>\n",
       "      <td>300</td>\n",
       "      <td>20750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20750 rows Ã— 1803 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6     \\\n",
       "0      0.004230 -0.000280 -0.013906 -0.002544  0.027433  0.058300  0.051670   \n",
       "1      0.012482  0.032496  0.067856  0.071552  0.078103  0.040353 -0.001059   \n",
       "2      0.012127  0.028458  0.062075  0.052611  0.022942 -0.010017 -0.023151   \n",
       "3      0.052964  0.074319  0.110670  0.108490  0.091825  0.056989  0.029337   \n",
       "4     -0.020462 -0.030787 -0.008617  0.008906  0.045046  0.042136  0.045037   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "20745  1.871600  1.648800  1.608900  1.802300  1.475000  1.390700  1.137800   \n",
       "20746  1.889400  2.022700  0.817300 -0.505840  2.462200  3.814200  2.661000   \n",
       "20747  1.269500  1.312200  0.725570  0.531290  0.958420 -0.049679  1.223100   \n",
       "20748 -5.562200 -2.797000 -2.353300 -3.075600 -4.136100 -4.028800 -0.580260   \n",
       "20749  0.838100 -1.211600 -0.567180 -0.555320 -0.644960 -0.232160  0.367070   \n",
       "\n",
       "           7         8         9     ...      1793      1794      1795  \\\n",
       "0      0.071857  0.080653  0.047917  ... -0.016692 -0.018566 -0.017361   \n",
       "1     -0.018580 -0.026813 -0.011280  ... -0.008210 -0.010408 -0.011459   \n",
       "2     -0.028515  0.005036  0.008450  ...  0.000915  0.000771 -0.002560   \n",
       "3     -0.016724 -0.042265 -0.053983  ... -0.001209  0.002878  0.000663   \n",
       "4      0.045182  0.025113  0.021730  ... -0.006369 -0.006614 -0.004698   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "20745  1.289600  0.963750  1.022200  ... -0.497640 -0.432590 -0.414760   \n",
       "20746  2.651200  1.991400  4.427300  ... -0.208820 -0.288930 -0.320880   \n",
       "20747  1.837000  0.989740  1.882600  ...  1.218500  1.125400  0.639470   \n",
       "20748  0.346070 -2.631700 -2.790000  ... -0.246670 -0.209020 -0.128670   \n",
       "20749 -0.040700  0.185980 -0.009721  ...  0.261620  0.119120  0.004095   \n",
       "\n",
       "           1796      1797      1798      1799  1800  1801   1802  \n",
       "0     -0.017919 -0.016680 -0.016650 -0.013097     0   300      1  \n",
       "1     -0.011747 -0.010394 -0.008070 -0.004354     0   300      2  \n",
       "2     -0.003020 -0.004190  0.000215  0.000850     0   300      3  \n",
       "3      0.000982 -0.002148 -0.009200 -0.010653     0   300      4  \n",
       "4     -0.007279 -0.006861 -0.006161 -0.006113     0   300      5  \n",
       "...         ...       ...       ...       ...   ...   ...    ...  \n",
       "20745 -0.363110 -0.329190 -0.460960 -0.621920     9   300  20746  \n",
       "20746 -0.379540 -0.408210 -0.507970 -0.548040     9   300  20747  \n",
       "20747  0.277320  0.172710 -0.002894  0.023955     9   300  20748  \n",
       "20748 -0.104730 -0.131960 -0.150780 -0.187320     9   300  20749  \n",
       "20749  0.006755  0.013448  0.027566  0.140510     9   300  20750  \n",
       "\n",
       "[20750 rows x 1803 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "df = read_csv('/home/jasmin/HAR/KU-HAR_time_domain_subsamples_20750x300.csv',header=None)\n",
    "df\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cd66060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pandas import drop\n",
    "df.drop([1801,1802], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f93665b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20750, 1801)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03eb3f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20750, 1800)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20750, 3601)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the new dataset in which we are adding fft cols i.e 1800 fft cols of signals\n",
    "# discrete fourier transform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "features = df.values[:,0:1800]\n",
    "labels = df.values[:,1800]\n",
    "\n",
    "fft = np.zeros(features.shape, dtype=np.float32)\n",
    "\n",
    "for i in range(0,len(features)):\n",
    "    for j in range(0, 6):\n",
    "        tmp = np.fft.fft(features[i, j*300:(j+1)*300])\n",
    "        fft[i, j*300:(j+1)*300] = abs(tmp)\n",
    "        \n",
    "print(fft.shape)\n",
    "\n",
    "# concatenating the fft and time domain signals - horizontal stacking\n",
    "\n",
    "features = pd.DataFrame(features)\n",
    "fft = pd.DataFrame(fft)\n",
    "labels = pd.DataFrame(labels)\n",
    "\n",
    "print(type(fft))\n",
    "print(type(features))\n",
    "\n",
    "df_new = pd.concat([features,fft], axis=1,ignore_index=True)\n",
    "\n",
    "#adding labesl to the new dataset\n",
    "\n",
    "df_new = pd.concat([df_new,labels], axis=1,ignore_index=True)\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "974add9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from numpy import dstack\n",
    "from tensorflow import keras\n",
    "#from utils import to_categorical\n",
    "\n",
    "\n",
    "# #stacking such that features are the 3rd dimension\n",
    "# function accepts a dataframe and number of cols(like 300,200 etc) for a single feature. returns a 3d numpy array\n",
    "def to_3d_input(df1, cols): \n",
    "    l=list()\n",
    "    for i in range(1,13):  # previously it was 7 after adding fft's 6 cols its now set to 13 i.e 12 cols\n",
    "        l.append(df1.loc[:,(i-1)*cols:i*cols-1])    # 0-299 accX, 300-599 accY, 600-899 accZ; 900-1199 gyrx, 1200-1499 gyry, 1500-1799 gyrz\n",
    "    X = dstack(l)\n",
    "    return X\n",
    "\n",
    "\n",
    "def split_dataset(df):  \n",
    "    #accepts a dataframe as parameter\n",
    "    # returns 4 dataframes\n",
    "    #spliting the dataset first\n",
    "    X = df.iloc[:,:-1]  # features\n",
    "    Y = df.iloc[:,-1]   # labels\n",
    "\n",
    "    print('Features shape : ',X.shape)\n",
    "    print('Label shape : ',Y.shape, end='\\n\\n')\n",
    "\n",
    "    labels = df[3600].unique() # can also replace it with arange(18)\n",
    "    features_train, features_test,label_train, label_test = DataFrame(),DataFrame(),DataFrame(),DataFrame()\n",
    "\n",
    "    for i in labels:\n",
    "        data = df[df[3600] == i]\n",
    "        rows = data.shape[0]\n",
    "        train = round(rows*0.95) # spliting dataset into 75% training and 25% test\n",
    "\n",
    "        #concatenating each class's train and test to \n",
    "        features_train = concat([features_train, data.iloc[:train]])\n",
    "        label_train = concat([label_train,data.iloc[:train,3600]])\n",
    "        features_test = concat([features_test,data.iloc[train:]])\n",
    "        label_test = concat([label_test,data.iloc[train:,3600]]) \n",
    "\n",
    "    print(\"After data split : \")\n",
    "    print('features_train : ',features_train.shape)\n",
    "    print('features_test : ',features_test.shape)\n",
    "    print('label_train : ',label_train.shape)\n",
    "    print('label_test : ',label_test.shape,end = '\\n\\n')\n",
    "    \n",
    "    #generating 3d input\n",
    "    features_train = to_3d_input(features_train, 300) # cols is 300 because its 3 sec dataset\n",
    "    features_test =to_3d_input(features_test, 300)\n",
    "    \n",
    "    #one hot encoding of labels\n",
    "    label_train = keras.utils.to_categorical(label_train)\n",
    "    label_test = keras.utils.to_categorical(label_test)\n",
    "    \n",
    "    print(\"After applying dstack and one hot encoding : \")\n",
    "    print('features_train : ',features_train.shape)\n",
    "    print('features_test : ',features_test.shape)\n",
    "    print('label_train : ',label_train.shape)\n",
    "    print('label_test : ',label_test.shape,end = '\\n\\n')\n",
    "\n",
    "    return features_train,features_test, label_train, label_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b171a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape :  (20750, 3600)\n",
      "Label shape :  (20750,)\n",
      "\n",
      "After data split : \n",
      "features_train :  (19712, 3601)\n",
      "features_test :  (1038, 3601)\n",
      "label_train :  (19712, 1)\n",
      "label_test :  (1038, 1)\n",
      "\n",
      "After applying dstack and one hot encoding : \n",
      "features_train :  (19712, 300, 12)\n",
      "features_test :  (1038, 300, 12)\n",
      "label_train :  (19712, 18)\n",
      "label_test :  (1038, 18)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#splitting the dataset\n",
    "X_train, X_test, Y_train, Y_test = split_dataset(df_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcc54eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0572bad4-b28d-4c20-b08f-315acab0ccef",
   "metadata": {},
   "source": [
    "### Model trained for 30 epochs - weighted f1 score 0.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "004a729b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_3 (GRU)                 (None, 300, 128)          54528     \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 300, 128)          99072     \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 128)               99072     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 18)                2322      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 254,994\n",
      "Trainable params: 254,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb68ca1fc10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.GRU(128, input_shape=X_train.shape[1:], return_sequences=True))\n",
    "model.add(layers.GRU(128, activation='relu', return_sequences=True))\n",
    "model.add(layers.GRU(128, activation='relu'))\n",
    "model.add(layers.Dense(18, activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=30, batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53f9201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e1a03b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1038, 18)\n",
      "(1038, 18)\n",
      "(1038,)\n",
      "(1038,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93        94\n",
      "           1       0.94      0.80      0.86        94\n",
      "           2       0.78      0.97      0.87        90\n",
      "           3       0.98      1.00      0.99        93\n",
      "           4       1.00      0.99      1.00       109\n",
      "           5       0.97      0.96      0.96        91\n",
      "           6       0.99      1.00      0.99        88\n",
      "           7       0.72      0.99      0.83        67\n",
      "           8       0.94      0.88      0.91        33\n",
      "           9       1.00      0.33      0.50        24\n",
      "          10       1.00      0.82      0.90        50\n",
      "          11       0.98      0.95      0.97        44\n",
      "          12       1.00      1.00      1.00        16\n",
      "          13       1.00      0.92      0.96        13\n",
      "          14       0.94      1.00      0.97        30\n",
      "          15       1.00      0.95      0.97        40\n",
      "          16       0.93      1.00      0.96        39\n",
      "          17       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           0.93      1038\n",
      "   macro avg       0.95      0.91      0.92      1038\n",
      "weighted avg       0.94      0.93      0.93      1038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ValueError: Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets\n",
    "# we do the following because to evaluate accuracy you need a vector of labels\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(y_predict.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "y_pred = np.argmax(y_predict, axis=1)\n",
    "y_test= np.argmax(Y_test, axis=1)\n",
    "print(y_pred.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff85ca7-79cc-4739-9f16-b0db3b2c7420",
   "metadata": {},
   "source": [
    "### Model trained for 40 epochs - weighted f1 score 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7f89839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_9 (GRU)                 (None, 300, 128)          54528     \n",
      "                                                                 \n",
      " gru_10 (GRU)                (None, 300, 128)          99072     \n",
      "                                                                 \n",
      " gru_11 (GRU)                (None, 128)               99072     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 18)                2322      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 254,994\n",
      "Trainable params: 254,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb6be6d7f40>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with higher epochs\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.GRU(128, input_shape=X_train.shape[1:], return_sequences=True))\n",
    "model.add(layers.GRU(128, activation='relu', return_sequences=True))\n",
    "model.add(layers.GRU(128, activation='relu'))\n",
    "model.add(layers.Dense(18, activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=40, batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfd65b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3914599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1038, 18)\n",
      "(1038, 18)\n",
      "(1038,)\n",
      "(1038,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        94\n",
      "           1       0.86      0.86      0.86        94\n",
      "           2       0.87      0.91      0.89        90\n",
      "           3       0.98      1.00      0.99        93\n",
      "           4       1.00      0.98      0.99       109\n",
      "           5       0.94      0.92      0.93        91\n",
      "           6       0.99      1.00      0.99        88\n",
      "           7       0.89      0.97      0.93        67\n",
      "           8       1.00      0.82      0.90        33\n",
      "           9       0.88      0.88      0.88        24\n",
      "          10       0.98      0.90      0.94        50\n",
      "          11       1.00      0.98      0.99        44\n",
      "          12       1.00      1.00      1.00        16\n",
      "          13       1.00      1.00      1.00        13\n",
      "          14       0.86      1.00      0.92        30\n",
      "          15       0.93      0.97      0.95        40\n",
      "          16       0.97      0.95      0.96        39\n",
      "          17       1.00      0.96      0.98        23\n",
      "\n",
      "    accuracy                           0.95      1038\n",
      "   macro avg       0.95      0.95      0.95      1038\n",
      "weighted avg       0.95      0.95      0.95      1038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(y_predict.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "y_pred = np.argmax(y_predict, axis=1)\n",
    "y_test= np.argmax(Y_test, axis=1)\n",
    "print(y_pred.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82387204-f675-46b1-851e-3d264c2ae67c",
   "metadata": {},
   "source": [
    "### Model trained for 50 epochs - weighted f1-score 0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86e51889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 10:02:46.670416: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/compiler/anaconda3/lib:/usr/local/cuda/lib64:/usr/local/cuda/lib64/openmpi:/apps/gcc/mpi/openmpi/3.0.0/lib64:/apps/gcc/mpi/openmpi/3.0.0/lib64/openmpi:/apps/gcc/compiler/mpich/3.4.2/lib64:/apps/gcc/compiler/mpich/3.4.2/lib64/openmpi\n",
      "2024-01-30 10:02:46.670499: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-01-30 10:02:46.671443: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 300, 128)          54528     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 300, 128)          99072     \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 128)               99072     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 18)                2322      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 254,994\n",
      "Trainable params: 254,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b544729d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with higher epochs - 50\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.GRU(128, input_shape=X_train.shape[1:], return_sequences=True))\n",
    "model.add(layers.GRU(128, activation='relu', return_sequences=True))\n",
    "model.add(layers.GRU(128, activation='relu'))\n",
    "model.add(layers.Dense(18, activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9d014ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62a3cf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1038, 18)\n",
      "(1038, 18)\n",
      "(1038,)\n",
      "(1038,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93        94\n",
      "           1       0.89      0.86      0.88        94\n",
      "           2       0.85      0.91      0.88        90\n",
      "           3       0.98      0.98      0.98        93\n",
      "           4       0.99      0.97      0.98       109\n",
      "           5       0.95      0.88      0.91        91\n",
      "           6       0.99      0.99      0.99        88\n",
      "           7       0.89      0.97      0.93        67\n",
      "           8       1.00      0.79      0.88        33\n",
      "           9       0.85      0.71      0.77        24\n",
      "          10       0.94      0.94      0.94        50\n",
      "          11       1.00      1.00      1.00        44\n",
      "          12       0.94      1.00      0.97        16\n",
      "          13       1.00      1.00      1.00        13\n",
      "          14       0.81      0.97      0.88        30\n",
      "          15       0.98      1.00      0.99        40\n",
      "          16       1.00      0.97      0.99        39\n",
      "          17       0.96      1.00      0.98        23\n",
      "\n",
      "    accuracy                           0.94      1038\n",
      "   macro avg       0.94      0.94      0.94      1038\n",
      "weighted avg       0.94      0.94      0.94      1038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(y_predict.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "y_pred = np.argmax(y_predict, axis=1)\n",
    "y_test= np.argmax(Y_test, axis=1)\n",
    "print(y_pred.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdbeaa4",
   "metadata": {},
   "source": [
    "### Model Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17294ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_6 (GRU)                 (None, 300, 128)          54528     \n",
      "                                                                 \n",
      " gru_7 (GRU)                 (None, 300, 150)          126000    \n",
      "                                                                 \n",
      " gru_8 (GRU)                 (None, 150)               135900    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 18)                2718      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 319,146\n",
      "Trainable params: 319,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb68c348be0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.GRU(128, input_shape=X_train.shape[1:], return_sequences=True))\n",
    "model.add(layers.GRU(150, activation='relu', return_sequences=True))\n",
    "model.add(layers.GRU(150, activation='relu'))\n",
    "model.add(layers.Dense(18, activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=30, batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a74b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1bb960d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1038, 18)\n",
      "(1038, 18)\n",
      "(1038,)\n",
      "(1038,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        94\n",
      "           1       0.92      0.84      0.88        94\n",
      "           2       0.84      0.89      0.86        90\n",
      "           3       0.97      0.98      0.97        93\n",
      "           4       0.96      0.97      0.97       109\n",
      "           5       0.93      0.97      0.95        91\n",
      "           6       1.00      0.90      0.95        88\n",
      "           7       0.96      0.97      0.96        67\n",
      "           8       0.93      0.79      0.85        33\n",
      "           9       0.95      0.79      0.86        24\n",
      "          10       0.83      0.96      0.89        50\n",
      "          11       1.00      0.98      0.99        44\n",
      "          12       0.94      1.00      0.97        16\n",
      "          13       1.00      1.00      1.00        13\n",
      "          14       0.83      1.00      0.91        30\n",
      "          15       0.97      0.93      0.95        40\n",
      "          16       0.93      1.00      0.96        39\n",
      "          17       0.96      1.00      0.98        23\n",
      "\n",
      "    accuracy                           0.93      1038\n",
      "   macro avg       0.94      0.94      0.94      1038\n",
      "weighted avg       0.94      0.93      0.93      1038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(y_predict.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "y_pred = np.argmax(y_predict, axis=1)\n",
    "y_test= np.argmax(Y_test, axis=1)\n",
    "print(y_pred.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e6455f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8748df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
